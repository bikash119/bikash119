{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6PRv9qm0Jf3R5IKTEIUNL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash119/bikash119/blob/main/learn_pytorch_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Goal : \n",
        "`python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS`\n",
        "\n",
        "Example `python train.py --model tinyvgg --batch_size 32 --lr 0.001 --num_epochs 10`"
      ],
      "metadata": {
        "id": "vYlBfj2zjwnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "deep_learning_classification_prj\n",
        "  ├── src\n",
        "  │   ├── data_setup.py\n",
        "  │   ├── train.py\n",
        "  │   ├── engine.py\n",
        "  │   ├── utils.py\n",
        "  │   ├── model.py\n",
        "  ├── model\n",
        "  │   ├── model_from_script.pth\n",
        "  │   ├── model_from_cells.pth\n",
        "  ├── data\n",
        "  │   ├── root_data_folder\n",
        "  │       ├── train\n",
        "  │           ├── class_a\n",
        "  │               ├── img_1.jpg|png\n",
        "  │               ├── ....\n",
        "  │               ├── img_n.jpg|png\n",
        "  │           ├── class_b\n",
        "  │           ├── class_c\n",
        "  └───────├── test\n",
        "              ├── class_a\n",
        "              ├── class_b\n",
        "              ├── class_c\n",
        "  \n",
        "</pre>\n"
      ],
      "metadata": {
        "id": "sG5WERVPkclF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell to download images from a github repo"
      ],
      "metadata": {
        "id": "kIOJsWOdpoKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "## Setup data folder\n",
        "root_path = Path(\"deep_learning_classification/data/\")\n",
        "img_path = root_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if img_path.is_dir():\n",
        "  print(f'{img_path} directory exists.')\n",
        "else:\n",
        "  print(f'Creating directory {img_path}')\n",
        "  img_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "## Download zip file \n",
        "with open(root_path/'pizz_steak_sushi.zip', 'wb') as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(f'Downloading zip file...')\n",
        "  f.write(request.content)\n",
        "\n",
        "## unzip the zip file\n",
        "with zipfile.ZipFile(root_path/'pizz_steak_sushi.zip', 'r' ) as zip_ref:\n",
        "  print(f'Unzipping data...')\n",
        "  zip_ref.extractall(img_path)\n",
        "\n",
        "## Remove zip file\n",
        "os.remove(root_path/'pizz_steak_sushi.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqNLOxUAkFp5",
        "outputId": "f2609e60-2c4d-4336-8909-e448246f727a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directory deep_learning_classification_prj/data/pizza_steak_sushi\n",
            "Downloading zip file...\n",
            "Unzipping data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create pytorch Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "MdYxYXbFuxMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deep_learning_classification/src/data_setup.py\n",
        "\"\"\"\n",
        "Contains functionality to create pytorch DataLoaders from image classification usecases\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "def create_dataloader(train_dir:str,\n",
        "                      test_dir: str,\n",
        "                      train_transforms: transforms.Compose,\n",
        "                      test_transforms: transforms.Compose,\n",
        "                      batch_size: int,\n",
        "                      num_workers: int) -> Tuple[DataLoader, DataLoader, List[str]]:\n",
        "  \"\"\"\n",
        "   Creates train and test dataloaders\n",
        "\n",
        "    Takes in training directory and testing directory and creates Pytorch Datasets which are then \n",
        "    used to create Pytorch DataLoaders\n",
        "\n",
        "    Args:\n",
        "      train_dr(str) : Folder containing images to be used for training the model\n",
        "      test_dir(str) : Folder containing images to be used for testing the model\n",
        "      train_transforms ( transforms.Compose) : Transformation to be applied on the images used for training\n",
        "      test_transform ( transforms.Compose) : Transformation to be applied on the images used for testing\n",
        "      batch_size(int) : Size of mini batch or Number of samples per batch in each DataLoaders\n",
        "      num_workers (int) : Number of workers per DataLoader ( mostly equals to the number of CPU)\n",
        "\n",
        "    Returns:\n",
        "      A Tuple containing \n",
        "        train_dataloader ( torch.utils.data.DataLoader): A pytorch DataLoader for training dataset\n",
        "        test_dataloader ( torch.utils.data.DataLoader) : A pytorch DataLoader for testing dataset\n",
        "        classes ( List[str]) : A list of string representing the image classes.\n",
        "    \n",
        "    Example usage:\n",
        "      train_dataloader, test_dataloader, classes = create_dataloaders(train_dir = path/to/train_img/folder,\n",
        "                                                                      test_dir = path/to/train_img/folder,\n",
        "                                                                      train_transforms= some_tranforms,\n",
        "                                                                      test_transforms = some_transforms,\n",
        "                                                                      batch_size= 32,\n",
        "                                                                      num_workers = 2)\n",
        "  \"\"\"\n",
        "\n",
        "  # Create pytorch datasets using images in train and test folder\n",
        "  train_dataset = datasets.ImageFolder(root=train_dir,\n",
        "                                       transform=train_transforms)\n",
        "  test_dataset = datasets.ImageFolder(root=test_dir,\n",
        "                                      transform=test_transforms)\n",
        "  \n",
        "  ## Get Image classes\n",
        "  classes = train_dataset.classes\n",
        "\n",
        "  # Create pytorch dataloaders from datasets\n",
        "  train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True,\n",
        "                                num_workers=NUM_WORKERS)\n",
        "  \n",
        "  test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                               batch_size=batch_size,\n",
        "                               shuffle=False,\n",
        "                               num_workers=NUM_WORKERS)\n",
        "  \n",
        "  return train_dataloader, test_dataloader, classes\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHV2QykwyTj3",
        "outputId": "ba536ab5-23aa-486e-c164-0c39bf05b14e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deep_learning_classification/src/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/deep_learning_classification')\n",
        "from src import data_setup\n",
        "from torchvision import transforms\n",
        "train_dir = img_path/'train'\n",
        "test_dir = img_path/'test'\n",
        "transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64))\n",
        "])\n",
        "train_dataloader , test_dataloader, classes = create_dataloader(train_dir= train_dir,\n",
        "                                                                test_dir = test_dir,\n",
        "                                                                train_transforms=transforms,\n",
        "                                                                test_transforms=transforms,\n",
        "                                                                batch_size=32,\n",
        "                                                                num_workers=NUM_WORKERS)\n",
        "\n",
        "train_dataloader, test_dataloader, classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk30i64C-GWI",
        "outputId": "ae986505-44de-4d2e-f8c1-9e6f144ead96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7fabf8ec6b30>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7fabf8ec7250>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make the model"
      ],
      "metadata": {
        "id": "bcjCOOT7FNGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deep_learning_classification/src/model.py\n",
        "\"\"\"\n",
        "  Contains the model architecture code\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "\n",
        "  \"\"\"\n",
        "    Create the TinyVGG architecure\n",
        "\n",
        "    Replicates the TinyVGG architecture from the CNN Explainer website in pytorch.\n",
        "    See the original architecture here: https://poloclub.github.io\n",
        "\n",
        "    Args:\n",
        "      input_shape(int) : An integer indicating number of input channels.\n",
        "      hidden_units(int) : An integer indicating number of hidden units between layers\n",
        "      output_shape(int) : An integer indicating number of classes\n",
        "\n",
        "    Example Usage\n",
        "      model_v0 = TinyVGG(input_shape=3,\n",
        "                         hidden_units=10,\n",
        "                         output_units=3)\n",
        "  \"\"\"\n",
        "  def __init__(self, \n",
        "               input_shape: int,\n",
        "               hidden_units:int,\n",
        "               output_shape: int) -> None:\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    self.classifier= nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units * 13 * 13,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x)-> torch.Tensor:\n",
        "    return self.classifier(self.block_2(self.block_1(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjahsogxCS7e",
        "outputId": "a54cb3f4-0dd0-4d75-846b-3375a2f24e46"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deep_learning_classification/src/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src import model\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model_v2 = TinyVGG(input_shape=3, \n",
        "                   hidden_units=10, \n",
        "                   output_shape=len(classes)).to(device)\n",
        "\n",
        "model_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaWsie2mKPLj",
        "outputId": "5b4e79e2-ca03-4a66-aaff-0dcfa1cfa7c2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_v2,input_size=[1,3,64,64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGA7XE8BKvuw",
        "outputId": "6ad5a754-a5ec-441d-ce40-0e1e3c4062d7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TinyVGG                                  [1, 3]                    --\n",
              "├─Sequential: 1-1                        [1, 10, 30, 30]           --\n",
              "│    └─Conv2d: 2-1                       [1, 10, 62, 62]           280\n",
              "│    └─ReLU: 2-2                         [1, 10, 62, 62]           --\n",
              "│    └─Conv2d: 2-3                       [1, 10, 60, 60]           910\n",
              "│    └─ReLU: 2-4                         [1, 10, 60, 60]           --\n",
              "│    └─MaxPool2d: 2-5                    [1, 10, 30, 30]           --\n",
              "├─Sequential: 1-2                        [1, 10, 13, 13]           --\n",
              "│    └─Conv2d: 2-6                       [1, 10, 28, 28]           910\n",
              "│    └─ReLU: 2-7                         [1, 10, 28, 28]           --\n",
              "│    └─Conv2d: 2-8                       [1, 10, 26, 26]           910\n",
              "│    └─ReLU: 2-9                         [1, 10, 26, 26]           --\n",
              "│    └─MaxPool2d: 2-10                   [1, 10, 13, 13]           --\n",
              "├─Sequential: 1-3                        [1, 3]                    --\n",
              "│    └─Flatten: 2-11                     [1, 1690]                 --\n",
              "│    └─Linear: 2-12                      [1, 3]                    5,073\n",
              "==========================================================================================\n",
              "Total params: 8,083\n",
              "Trainable params: 8,083\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 5.69\n",
              "==========================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 0.71\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 0.79\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Training engine."
      ],
      "metadata": {
        "id": "XGP_aVffbSMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deep_learning_classification/src/engine.py\n",
        "\"\"\"\n",
        "  Contains function for training and testing a pytorch model\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "\n",
        "def train_step(model: nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device\n",
        "               )-> Tuple[float, float]:\n",
        "  \"\"\"\n",
        "    Trains a pytorch model for single Epoch\n",
        "\n",
        "    Turns a target Pytorch model to training mode and then executes all the training steps\n",
        "    forward pass,\n",
        "    loss calculation,\n",
        "    zero gradient,\n",
        "    backpropagation\n",
        "    update parameters\n",
        "    Args:\n",
        "      model(nn.Module): Model to be trained\n",
        "      dataloader(torch.utils.data.DataLoader) : A DataLoader to be used for training the model\n",
        "      loss_fn(nn.Module) : A function to calculate the loss\n",
        "      optimizer(torch.optim.Optimzer) : A pytorch optimizer to help minimize the loss\n",
        "      device(torch. device) : A target device to compute on 'cpu' or 'cuda'\n",
        "    \n",
        "    Returns:\n",
        "      A tuple of training loss and training accuracy metrics in the form of\n",
        "      (training_loss, training_acc)\n",
        "\n",
        "    Example Usage : \n",
        "      train_loss, train_acc = train_step(model=model_v0, \n",
        "                                         dataloader=train_dataloader,\n",
        "                                         loss_fn= nn.CrossEntropyLoss(),\n",
        "                                         optimizer=torch.optim.Adam(params=model_v0.parameters(),lr=0.001),\n",
        "                                         device='cuda'\n",
        "      )\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  #Put the model to train mode\n",
        "  model.train()\n",
        "\n",
        "  #Setup the train loss and train accuracy\n",
        "  train_loss, train_acc = 0,0\n",
        "\n",
        "  # Iterate over the dataloader\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "\n",
        "    #send data to device\n",
        "    X,y = X.to(device),y.to(device)\n",
        "\n",
        "    #Forward pass\n",
        "    pred_logits = model(X)\n",
        "\n",
        "    # Calculate Loss\n",
        "    loss = loss_fn(pred_logits, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Calculate Acc\n",
        "    pred_label = torch.argmax(torch.softmax(pred_logits,dim=1),dim=1)\n",
        "    train_acc += (pred_label == y).sum().item()/ len(pred_logits)\n",
        "\n",
        "    # Zero gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Back prop\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "\n",
        "  return train_loss, train_acc\n",
        "\n",
        "\n",
        "def test_step(model: nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              device:torch.device)-> Tuple[float,float]:\n",
        "\n",
        "    \"\"\"\n",
        "    Tests a pytorch model for single Epoch\n",
        "\n",
        "    Turns a target Pytorch model to eval mode and then executes all the testing steps\n",
        "    forward pass,\n",
        "    loss calculation,\n",
        "    \n",
        "    Args:\n",
        "      model(nn.Module): Model to be trained\n",
        "      dataloader(torch.utils.data.DataLoader) : A DataLoader to be used for testing the model\n",
        "      loss_fn(nn.Module) : A function to calculate the loss\n",
        "      device(torch. device) : A target device to compute on 'cpu' or 'cuda'\n",
        "    \n",
        "    Returns:\n",
        "      A tuple of testing loss and testing accuracy metrics in the form of\n",
        "      (testing_loss, testing_acc)\n",
        "\n",
        "    Example Usage : \n",
        "      test_loss, test_acc = test_step(model=model_v0, \n",
        "                                         dataloader=train_dataloader,\n",
        "                                         loss_fn= nn.CrossEntropyLoss(),\n",
        "                                         device='cuda'\n",
        "      )\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "    #Put the model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Intialize the test_loss and test_acc\n",
        "    test_loss, test_acc = 0,0\n",
        "    \n",
        "    #Turn on the inference context manager\n",
        "    with torch.inference_mode():\n",
        "      \n",
        "      # Loop over the dataloader\n",
        "      for batch,(X,y) in enumerate(dataloader):\n",
        "        \n",
        "        # Send data to target device\n",
        "        X,y = X.to(device),y.to(device)\n",
        "\n",
        "        \n",
        "        # Forward pass\n",
        "        pred_logits = model(X)\n",
        "\n",
        "        # Calculate Loss\n",
        "        loss = loss_fn(pred_logits,y)\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        # Calculate acc\n",
        "        pred_labels = torch.argmax(torch.softmax(pred_logits,dim=1),dim=1)\n",
        "        test_acc += (pred_labels == y).sum().item()/ len(pred_labels) \n",
        "\n",
        "      # Calculate the avg loss and accuracy across all batches.  \n",
        "      test_loss /= len(dataloader)\n",
        "      test_acc /= len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          loss_fn: nn.Module,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          device: torch.device,\n",
        "          epochs: int) -> Dict[str,List[float]]\n",
        "  \n",
        "  \"\"\"\n",
        "    Trains and Tests the pytorch model\n",
        "\n",
        "    Passes a pytorch model through the train_step and the test_step function for\n",
        "    a epochs number of times.\n",
        "    Args:\n",
        "      model(nn.Module): Model to be trained\n",
        "      train_dataloader(torch.utils.data.DataLoader) : A DataLoader to be used for training the model\n",
        "      test_dataloader(torch.utils.data.DataLoader) : A DataLoader to be used for testing the model\n",
        "      loss_fn(nn.Module) : A function to calculate the loss\n",
        "      optimizer(torch.optim.Optimzer) : A pytorch optimizer to help minimize the loss\n",
        "      device(torch.device) : A target device to compute on 'cpu' or 'cuda'\n",
        "      epochs(int): Number of times the model should pass over the training and the testing dataset.\n",
        "    \n",
        "    Returns:\n",
        "      A dictionary containing the train_loss, train_acc, test_loss & test_acc. \n",
        "      Each metrics have a value in list for each epoch\n",
        "\n",
        "      The output form :\n",
        "        {\n",
        "          train_loss : List[float]\n",
        "          train_acc : List[float]\n",
        "          test_loss : List[float]\n",
        "          test_acc : List[float]\n",
        "        }\n",
        "  \n",
        "  \"\"\"\n",
        "  # Create a empty dictionary to hold the results\n",
        "\n",
        "  results = {\n",
        "      'train_loss':[]\n",
        "      ,'train_acc':[]\n",
        "      ,'test_loss':[]\n",
        "      ,'test_acc':[]\n",
        "  }\n",
        "\n",
        "  \n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss , train_acc = train_step(model=model,\n",
        "                                        dataloader=train_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        optimizer=optimizer,\n",
        "                                        device=device)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "\n",
        "    print(f'Epoch : {epoch+1} |'\n",
        "          f'train_loss : {train_loss:.4f} |'\n",
        "          f'train_acc : {train_acc:.4f} |'\n",
        "          f'test_loss : {test_loss:.4f} |'\n",
        "          f'test_acc : {test_acc:.4f} |' \n",
        "    )\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_acc'].append(train_loss)\n",
        "    results['test_loss'].append(train_loss)\n",
        "    results['test_acc'].append(train_loss)\n",
        "  \n",
        "  return results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ttaq8NbQyD",
        "outputId": "06bd73d2-09e6-4923-d0b8-1f8100fe0d93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deep_learning_classification/src/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deep_learning_classification/src/utils.py\n",
        "\"\"\"\n",
        "  Contains various utility functions for pytorch model training and saving\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "\n",
        "def save_mode(model: nn.Module,\n",
        "              target_dir: str,\n",
        "              model_name: str):\n",
        "  \"\"\"\n",
        "    Saves a pytorch model to a target directory\n",
        "    Args:\n",
        "      model (nn.Module): a pytorch model to be saved\n",
        "      target_dir (str): A directory for saving the model\n",
        "      model_name (str): The filename to given to the model. Should include either \n",
        "                        .pt or .pth as the file extension \n",
        "\n",
        "    Returns : None\n",
        "\n",
        "    Example usage\n",
        "      save_model(model=model_0,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"deep_learning_classification.pth\")\n",
        "  \"\"\"\n",
        "\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "  # Create model save path\n",
        "  assert model_name.endswith('.pt') or model_name.endswith('pth'),\"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  # Save the model state_dict()\n",
        "  print(f'[INFO] Saving model to : {model_save_path}')\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCFxfv5pU5Sx",
        "outputId": "4e19defd-aa4f-4c06-c269-04db64e5cda2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deep_learning_classification/src/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYSfiPcl5xns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}